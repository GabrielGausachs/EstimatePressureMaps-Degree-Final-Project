{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUATION FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This file is to evaluate the loaded models with an specific validation keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.functional import crop\n",
    "import gc\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from Utils.logger import initialize_logger, get_logger\n",
    "from scipy import signal\n",
    "from Utils.config import (\n",
    "    IMG_PATH,\n",
    "    PATH_DATASET,\n",
    "    SERVER_SLP_DATASET_PATH,\n",
    "    USE_PHYSICAL_DATA,\n",
    ")\n",
    "\n",
    "from Utils import (\n",
    "    metrics,\n",
    ")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(USE_PHYSICAL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the paths of the test arrays\n",
    "\n",
    "import json\n",
    "\n",
    "def read_json(f):\n",
    "    data = json.load(f)\n",
    "    if PATH_DATASET == 'Server':\n",
    "        return data\n",
    "    else:\n",
    "        dic_paths = {}\n",
    "\n",
    "        for key, paths in data.items():\n",
    "            dic_paths[key] = []\n",
    "            for i, path in enumerate(paths):\n",
    "                parts = path.split(\"danaLab\", 2) \n",
    "                result = \"SLP\".join(parts[1:]).lstrip('/')\n",
    "                modified_path = os.path.join(LOCAL_SLP_DATASET_PATH, result)\n",
    "                dic_paths[key].append(modified_path)\n",
    "\n",
    "        print(dic_paths)\n",
    "        \n",
    "        return dic_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all the files of an especific cover or an especific patient\n",
    "\n",
    "covers = ['cover1','cover2','uncover']\n",
    "\n",
    "def filter_files(dic,filter):\n",
    "    if filter is not None:\n",
    "        filter_dic = {}\n",
    "        for key, paths in dic.items():\n",
    "            filter_dic[key]=[]\n",
    "            for path in paths:\n",
    "                if filter in path:\n",
    "                    filter_dic[key].append(path)\n",
    "        return filter_dic\n",
    "    else:\n",
    "        return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    # Dataset for the random option\n",
    "    # Includes:\n",
    "    # - IR arrays\n",
    "    # - PR arrays\n",
    "    # Physical data\n",
    "    def __init__(self, ir_paths, pm_paths, p_data, transform=None):\n",
    "\n",
    "        self.ir_paths = ir_paths\n",
    "        self.pm_paths = pm_paths\n",
    "        self.p_data = p_data\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ir_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        input_path = self.ir_paths[index]\n",
    "        output_path = self.pm_paths[index]\n",
    "\n",
    "        input_array = self.load_array(input_path)\n",
    "        output_array = self.load_array(output_path)\n",
    "        input_array = input_array.astype(np.float32)\n",
    "        output_array = output_array.astype(np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            input_array = self.transform['input'](input_array)\n",
    "\n",
    "            if PATH_DATASET == 'Server':\n",
    "                parts = str(output_path.split(\"/\")[-4])\n",
    "            else:\n",
    "                parts = str(output_path.split(\"\\\\\")[-4])\n",
    "            number = int(parts)\n",
    "            p_vector = self.p_data.iloc[number-1]\n",
    "            weight = p_vector[1]\n",
    "            tensor_data = torch.tensor(p_vector.values)\n",
    "\n",
    "            # Applying median filter\n",
    "            median_array = signal.medfilt2d(output_array)\n",
    "            max_array = np.maximum(output_array, median_array)\n",
    "\n",
    "            area_m = 1.03226 / 10000\n",
    "            ideal_pressure = weight * 9.81 / (area_m * 1000)\n",
    "\n",
    "            output_array = (max_array / np.sum(max_array)) * ideal_pressure\n",
    "            output_array = self.transform['output'](output_array)\n",
    "\n",
    "            if USE_PHYSICAL_DATA:\n",
    "                return input_array, output_array, tensor_data\n",
    "            else:\n",
    "                return input_array, output_array\n",
    "\n",
    "    def load_array(self, path):\n",
    "        # Load the array\n",
    "        array = np.load(path)\n",
    "        return array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the files that we want and do the transforms and create a dataloader to pass the model\n",
    "\n",
    "def crop_array(array):\n",
    "        return crop(array,7, 29, 140, 66)\n",
    "\n",
    "\n",
    "def create_dataloader(dic,p_data,transform):\n",
    "    \n",
    "    dataset = CustomDataset(dic['ir'], dic['pm'], p_data, transform=transform)\n",
    "    print('Len dataset:',len(dataset))\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "            dataset, batch_size=1, shuffle=False, num_workers=0, drop_last=True)\n",
    "    \n",
    "    test_dataset_info = {\n",
    "        'Number of samples': len(test_loader.dataset),\n",
    "        'Batch size': test_loader.batch_size,\n",
    "        'Number of batches': len(test_loader)\n",
    "        }\n",
    "    \n",
    "    print(f\"Val loader info: {test_dataset_info}\")\n",
    "\n",
    "    return test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate with a model loaded the files that we want with the metrics\n",
    "\n",
    "def evaluation(use_physical_data,model,model_file,metrics,test_loader,save):\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_file, map_location=torch.device('cpu')))\n",
    "        model.to(DEVICE)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"An error occurred while reading the file: {e}\")\n",
    "    else:\n",
    "        print('Model Loaded')\n",
    "\n",
    "    total_metric = [0, 0]\n",
    "\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()  # Clean CUDA Cache if used GPU\n",
    "    gc.collect()  # Collect trash to free memory not used\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if not use_physical_data:\n",
    "\n",
    "            for batch_idx, (input_images, target_images) in enumerate(test_loader, 1):\n",
    "    \n",
    "                input_img = input_images.to(DEVICE)\n",
    "                target_img = target_images.to(DEVICE)\n",
    "    \n",
    "                output_img = model(input_img)\n",
    "    \n",
    "                for i, metric in enumerate(metrics):\n",
    "    \n",
    "                    test_metric = metric(output_img, target_img)\n",
    "    \n",
    "                    total_metric[i] += test_metric\n",
    "    \n",
    "                # Free memory in each iteration\n",
    "                torch.cuda.empty_cache()  # Clean CUDA Cache if used GPU\n",
    "                gc.collect()  # Collect trash to free memory not used\n",
    "\n",
    "        else:\n",
    "    \n",
    "            for batch_idx, (input_images, target_images,tensor_data) in enumerate(test_loader, 1):\n",
    "        \n",
    "                input_img = input_images.to(DEVICE)\n",
    "                target_img = target_images.to(DEVICE)\n",
    "                tensor_data = tensor_data.to(DEVICE)\n",
    "                \n",
    "        \n",
    "                output_img = model(input_img,tensor_data)\n",
    "        \n",
    "                for i, metric in enumerate(metrics):\n",
    "        \n",
    "                    test_metric = metric(output_img, target_img)\n",
    "        \n",
    "                    total_metric[i] += test_metric\n",
    "        \n",
    "                # Free memory in each iteration\n",
    "                torch.cuda.empty_cache()  # Clean CUDA Cache if used GPU\n",
    "                gc.collect()  # Collect trash to free memory not used\n",
    "\n",
    "    print('Evaluation completed')\n",
    "    epoch_metric = [(total_metric[0] /\n",
    "                    len(test_loader)).item(), total_metric[1] / len(test_loader)]\n",
    "    \n",
    "    print(metrics)\n",
    "    print(epoch_metric)\n",
    "    \n",
    "    m_str = [f\"MSE - {epoch_metric[0]:.2f}\", f\"PerCS - {epoch_metric[1]:.2f}\"]\n",
    "    \n",
    "    m_str = \", \".join(m_str)\n",
    "    \n",
    "    print(m_str)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    axes[0].imshow(input_images.squeeze().cpu().numpy())\n",
    "    axes[0].set_title('Input Image')\n",
    "\n",
    "    axes[1].imshow(target_images.squeeze().cpu().numpy())\n",
    "    axes[1].set_title('Target Image')\n",
    "\n",
    "    axes[2].imshow(output_img.squeeze().cpu().numpy())\n",
    "    axes[2].set_title('Output Image')\n",
    "\n",
    "    fig.suptitle('Example of Input, Target and Output Image', fontsize=12)\n",
    "    fig.text(0.5, 0.01, f': {m_str}', ha='center')\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(IMG_PATH,'Comparing_output_model.png'))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execute this function to do an evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len dataset: 306\n",
      "Val loader info: {'Number of samples': 306, 'Batch size': 1, 'Number of batches': 306}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "An error occurred while reading the file: Error(s) in loading state_dict for UNET_phy:\n\tsize mismatch for phyNet.0.weight: copying a param with shape torch.Size([9, 9]) from checkpoint, the shape in current model is torch.Size([9, 11]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9e002efe5334>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(use_physical_data, model, model_file, metrics, test_loader, save)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DADES/ggausachs/ggausachs_env_tfg/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2154\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UNET_phy:\n\tsize mismatch for phyNet.0.weight: copying a param with shape torch.Size([9, 9]) from checkpoint, the shape in current model is torch.Size([9, 11]).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3bb5dd81a7f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Do the evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUSE_PHYSICAL_DATA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9e002efe5334>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(use_physical_data, model, model_file, metrics, test_loader, save)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"An error occurred while reading the file: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Loaded'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: An error occurred while reading the file: Error(s) in loading state_dict for UNET_phy:\n\tsize mismatch for phyNet.0.weight: copying a param with shape torch.Size([9, 9]) from checkpoint, the shape in current model is torch.Size([9, 11])."
     ]
    }
   ],
   "source": [
    "from Models import (\n",
    "    UNet,\n",
    "    Simple_net,\n",
    "    UNet_phy\n",
    ")\n",
    "\n",
    "# Variables\n",
    "#USE_PHYSICAL_DATA = True\n",
    "MODEL_NAME = \"UNet_phy\"\n",
    "name_model = \"UNetPDataMSE%PLoss_Type2_20240514173939.pth\"\n",
    "test_json = \"test_paths_20240514160422.json\"\n",
    "\n",
    "\n",
    "# Models\n",
    "models = {\"Simple_net\": Simple_net.Simple_net,\n",
    "          \"UNet\": UNet.UNET, \"UNet_phy\": UNet_phy.UNET_phy}\n",
    "\n",
    "# Metrics\n",
    "m = [\n",
    "    torch.nn.MSELoss(),\n",
    "    metrics.PerCS()\n",
    "]\n",
    "\n",
    "# Create the model\n",
    "if USE_PHYSICAL_DATA:\n",
    "        model = models[MODEL_NAME](1, 11, 1).to(DEVICE)\n",
    "else:\n",
    "        model = models[MODEL_NAME](1, 1).to(DEVICE)\n",
    "\n",
    "# Load the model\n",
    "model_file = os.path.join(os.path.join((os.getcwd()),'Models/SavedModels'),name_model)\n",
    "\n",
    "# Get the test paths\n",
    "f = open(os.path.join(os.path.join((os.getcwd()),'Models/TestJson'),test_json))\n",
    "dic_paths =read_json(f)\n",
    "filter_dic = filter_files(dic_paths,'cover1')\n",
    "\n",
    "# Get the pdata\n",
    "if PATH_DATASET == 'Server':\n",
    "    path_arrays = SERVER_SLP_DATASET_PATH\n",
    "else:\n",
    "    path_arrays = LOCAL_SLP_DATASET_PATH\n",
    "\n",
    "p_data = pd.read_csv(os.path.join(path_arrays, 'physiqueData.csv'))\n",
    "p_data = p_data.drop('sub_idx', axis=1)\n",
    "p_data = p_data.drop('gender',axis = 1)\n",
    "\n",
    "# Data transformation if needed\n",
    "transform = {\n",
    "        'input': transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Lambda(crop_array),  \n",
    "                    transforms.Resize((192, 84)),\n",
    "\t\t            transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "                    ]),\n",
    "        'output': transforms.Compose([transforms.ToTensor()])}\n",
    "\n",
    "# Create dataloader\n",
    "test_loader = create_dataloader(filter_dic,p_data,transform)\n",
    "\n",
    "# Do the evaluation\n",
    "evaluation(USE_PHYSICAL_DATA,model,model_file,m,test_loader,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
