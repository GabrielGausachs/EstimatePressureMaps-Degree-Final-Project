2024-05-23 10:42:59,332 - root - INFO -> Logger initialized in filename 2024-05-23-10-42-59
2024-05-23 10:42:59,332 - root - INFO -> --------------------------------------------------
2024-05-23 10:42:59,332 - root - INFO -> Reading the data from Server...
2024-05-23 10:42:59,370 - root - INFO -> Number of pacients: 102
2024-05-23 10:42:59,370 - root - INFO -> Number of categories in a patient: 3
2024-05-23 10:42:59,374 - root - INFO -> Size of the physical dataset: (102, 9)
2024-05-23 10:42:59,374 - root - INFO -> --------------------------------------------------
2024-05-23 10:42:59,375 - root - INFO -> Creating dataset...
2024-05-23 10:42:59,375 - root - INFO -> Partition --> Patients
2024-05-23 10:42:59,380 - root - INFO -> Train size: 10098
2024-05-23 10:42:59,380 - root - INFO -> Val size: 2754
2024-05-23 10:42:59,380 - root - INFO -> --------------------------------------------------
2024-05-23 10:42:59,380 - root - INFO -> Creating dataloaders...
2024-05-23 10:42:59,381 - root - INFO -> Train loader info: {'Number of samples': 10098, 'Batch size': 32, 'Number of batches': 315}
2024-05-23 10:42:59,460 - root - INFO -> Array input size of the train loader: torch.Size([32, 1, 192, 84])
2024-05-23 10:42:59,510 - root - INFO -> Array output size of the train loader: torch.Size([32, 1, 192, 84])
2024-05-23 10:42:59,510 - root - INFO -> Val loader info: {'Number of samples': 2754, 'Batch size': 32, 'Number of batches': 86}
2024-05-23 10:42:59,558 - root - INFO -> Array input size of the val loader: torch.Size([32, 1, 192, 84])
2024-05-23 10:42:59,608 - root - INFO -> Array output size of the val loader: torch.Size([32, 1, 192, 84])
2024-05-23 10:43:02,242 - root - INFO -> --------------------------------------------------
2024-05-23 10:43:02,242 - root - INFO -> Wandb correctly initialized
2024-05-23 10:43:03,595 - root - INFO -> --------------------------------------------------
2024-05-23 10:43:03,596 - root - INFO -> Starting training with model UNet that has 31036481 parameters
2024-05-23 10:43:03,596 - root - INFO -> Learning rate: 0.002
2024-05-23 10:43:03,596 - root - INFO -> --- Epoch: 0 ---
2024-05-23 10:43:03,596 - root - INFO -> Epoch: 0/100, Starting training...
2024-05-23 10:43:03,596 - root - INFO -> Loader length: 315
2024-05-23 10:43:03,596 - root - INFO -> Loader batch size: 32
2024-05-23 10:43:03,596 - root - INFO -> Loader drop last: True
2024-05-23 10:43:03,596 - root - INFO -> Loader num workers: 0
2024-05-23 10:43:03,596 - root - INFO -> Criterion: MSELoss()
2024-05-23 10:43:03,596 - root - INFO -> Physical loss: None
2024-05-23 10:43:03,698 - root - INFO -> Memory cleaned!
2024-05-23 10:44:35,663 - root - INFO -> Epoch: 0/100, Train loss = 175.400447
2024-05-23 10:44:35,663 - root - INFO -> Epoch: 0/100, Train MSELoss() = 175.400421
2024-05-23 10:44:35,663 - root - INFO -> Epoch: 0/100, Train PerCS() = 0.856660
2024-05-23 10:44:35,663 - root - INFO -> Epoch: 0/100, Train MSEeff() = 1198.986572
2024-05-23 10:44:35,759 - root - INFO -> Train finished! Memory cleaned!
2024-05-23 10:44:35,759 - root - INFO -> --------------------------------------------------
2024-05-23 10:44:35,760 - root - INFO -> Epoch: 0/100, Starting validation...
2024-05-23 10:44:35,760 - root - INFO -> Loader length: 86
2024-05-23 10:44:35,760 - root - INFO -> Loader batch size: 32
2024-05-23 10:44:35,760 - root - INFO -> Loader drop last: True
2024-05-23 10:44:35,760 - root - INFO -> Loader num workers: 0
2024-05-23 10:44:35,760 - root - INFO -> Metrics: [MSELoss(), PerCS(), MSEeff()]
2024-05-23 10:44:35,760 - root - INFO -> Physical loss: None
2024-05-23 10:44:35,855 - root - INFO -> Memory cleaned!
2024-05-23 10:44:52,503 - root - INFO -> Epoch: 0/100, Val loss = 166.053711
2024-05-23 10:44:52,503 - root - INFO -> Epoch: 0/100, Val MSELoss() = 166.053726
2024-05-23 10:44:52,503 - root - INFO -> Epoch: 0/100, Val PerCS() = 0.871808
2024-05-23 10:44:52,503 - root - INFO -> Epoch: 0/100, Val MSEeff() = 1129.917725
2024-05-23 10:44:52,598 - root - INFO -> Validation finished! Memory cleaned!
2024-05-23 10:44:52,598 - root - INFO -> --------------------------------------------------
2024-05-23 10:44:52,599 - root - INFO -> Learning rate: 0.002
2024-05-23 10:44:52,606 - root - INFO -> --- Epoch: 1 ---
2024-05-23 10:44:52,606 - root - INFO -> Epoch: 1/100, Starting training...
2024-05-23 10:44:52,607 - root - INFO -> Loader length: 315
2024-05-23 10:44:52,607 - root - INFO -> Loader batch size: 32
2024-05-23 10:44:52,607 - root - INFO -> Loader drop last: True
2024-05-23 10:44:52,607 - root - INFO -> Loader num workers: 0
2024-05-23 10:44:52,607 - root - INFO -> Criterion: MSELoss()
2024-05-23 10:44:52,607 - root - INFO -> Physical loss: None
2024-05-23 10:44:52,704 - root - INFO -> Memory cleaned!
