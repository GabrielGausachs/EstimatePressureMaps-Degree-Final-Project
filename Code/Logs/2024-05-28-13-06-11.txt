2024-05-28 13:06:13,751 - root - INFO -> Logger initialized in filename 2024-05-28-13-06-13
2024-05-28 13:06:13,751 - root - INFO -> --------------------------------------------------
2024-05-28 13:06:13,752 - root - INFO -> Reading the data from Server...
2024-05-28 13:06:13,836 - root - INFO -> Number of pacients: 102
2024-05-28 13:06:13,836 - root - INFO -> Number of categories in a patient: 3
2024-05-28 13:06:13,844 - root - INFO -> Size of the physical dataset: (102, 9)
2024-05-28 13:06:13,844 - root - INFO -> --------------------------------------------------
2024-05-28 13:06:13,844 - root - INFO -> Creating dataset...
2024-05-28 13:06:13,844 - root - INFO -> Partition --> Patients
2024-05-28 13:06:29,186 - root - INFO -> Train size: 10098
2024-05-28 13:06:29,186 - root - INFO -> Val size: 2754
2024-05-28 13:06:29,186 - root - INFO -> --------------------------------------------------
2024-05-28 13:06:29,186 - root - INFO -> Creating dataloaders...
2024-05-28 13:06:29,238 - root - INFO -> Train loader info: {'Number of samples': 10098, 'Batch size': 32, 'Number of batches': 315}
2024-05-28 13:06:29,259 - root - INFO -> Array input size of the train loader: torch.Size([32, 1, 192, 84])
2024-05-28 13:06:29,279 - root - INFO -> Array output size of the train loader: torch.Size([32, 1, 192, 84])
2024-05-28 13:06:29,279 - root - INFO -> Val loader info: {'Number of samples': 2754, 'Batch size': 32, 'Number of batches': 86}
2024-05-28 13:06:29,298 - root - INFO -> Array input size of the val loader: torch.Size([32, 1, 192, 84])
2024-05-28 13:06:29,317 - root - INFO -> Array output size of the val loader: torch.Size([32, 1, 192, 84])
2024-05-28 13:06:30,626 - root - INFO -> --------------------------------------------------
2024-05-28 13:06:30,626 - root - INFO -> Starting training with model UNet that has 7762465 parameters
2024-05-28 13:06:30,626 - root - INFO -> Learning rate: 0.002
2024-05-28 13:06:30,626 - root - INFO -> --- Epoch: 0 ---
2024-05-28 13:06:30,626 - root - INFO -> Epoch: 0/1, Starting training...
2024-05-28 13:06:30,626 - root - INFO -> Loader length: 315
2024-05-28 13:06:30,626 - root - INFO -> Loader batch size: 32
2024-05-28 13:06:30,626 - root - INFO -> Loader drop last: True
2024-05-28 13:06:30,626 - root - INFO -> Loader num workers: 0
2024-05-28 13:06:30,626 - root - INFO -> Criterion: MSELoss()
2024-05-28 13:06:30,626 - root - INFO -> Physical loss: None
2024-05-28 13:06:30,740 - root - INFO -> Memory cleaned!
2024-05-28 13:07:34,694 - root - INFO -> Epoch: 0/1, Train loss = 0.002597
2024-05-28 13:07:34,694 - root - INFO -> Epoch: 0/1, Train MSELoss() = 0.002597
2024-05-28 13:07:34,695 - root - INFO -> Epoch: 0/1, Train PerCS() = 0.642368
2024-05-28 13:07:34,695 - root - INFO -> Epoch: 0/1, Train MSEeff() = 0.011319
2024-05-28 13:07:34,794 - root - INFO -> Train finished! Memory cleaned!
2024-05-28 13:07:34,794 - root - INFO -> --------------------------------------------------
2024-05-28 13:07:34,795 - root - INFO -> Epoch: 0/1, Starting validation...
2024-05-28 13:07:34,795 - root - INFO -> Loader length: 86
2024-05-28 13:07:34,795 - root - INFO -> Loader batch size: 32
2024-05-28 13:07:34,795 - root - INFO -> Loader drop last: True
2024-05-28 13:07:34,795 - root - INFO -> Loader num workers: 0
2024-05-28 13:07:34,795 - root - INFO -> Metrics: [MSELoss(), PerCS(), MSEeff()]
2024-05-28 13:07:34,795 - root - INFO -> Physical loss: None
2024-05-28 13:07:34,892 - root - INFO -> Memory cleaned!
2024-05-28 13:07:47,220 - root - INFO -> Epoch: 0/1, Val loss = 0.000248
2024-05-28 13:07:47,220 - root - INFO -> Epoch: 0/1, Val MSELoss() = 0.000248
2024-05-28 13:07:47,220 - root - INFO -> Epoch: 0/1, Val PerCS() = 0.826362
2024-05-28 13:07:47,220 - root - INFO -> Epoch: 0/1, Val MSEeff() = 0.010405
2024-05-28 13:07:47,323 - root - INFO -> Validation finished! Memory cleaned!
2024-05-28 13:07:47,323 - root - INFO -> --------------------------------------------------
2024-05-28 13:07:47,323 - root - INFO -> Learning rate: 0.002
2024-05-28 13:07:47,331 - root - INFO -> Saving the model
2024-05-28 13:07:47,391 - root - INFO -> Model saved in /home/ggausachs/TFG/Code/Models/SavedModels
2024-05-28 13:07:47,391 - root - INFO -> --------------------------------------------------
