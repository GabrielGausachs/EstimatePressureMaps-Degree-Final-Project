2024-05-28 13:08:22,583 - root - INFO -> Logger initialized in filename 2024-05-28-13-08-22
2024-05-28 13:08:22,583 - root - INFO -> --------------------------------------------------
2024-05-28 13:08:22,583 - root - INFO -> Reading the data from Server...
2024-05-28 13:08:22,620 - root - INFO -> Number of pacients: 102
2024-05-28 13:08:22,620 - root - INFO -> Number of categories in a patient: 3
2024-05-28 13:08:22,627 - root - INFO -> Size of the physical dataset: (102, 9)
2024-05-28 13:08:22,627 - root - INFO -> --------------------------------------------------
2024-05-28 13:08:22,627 - root - INFO -> Creating dataset...
2024-05-28 13:08:22,627 - root - INFO -> Partition --> Patients
2024-05-28 13:08:38,113 - root - INFO -> Train size: 10098
2024-05-28 13:08:38,113 - root - INFO -> Val size: 2754
2024-05-28 13:08:38,113 - root - INFO -> --------------------------------------------------
2024-05-28 13:08:38,113 - root - INFO -> Creating dataloaders...
2024-05-28 13:08:38,167 - root - INFO -> Train loader info: {'Number of samples': 10098, 'Batch size': 32, 'Number of batches': 315}
2024-05-28 13:08:38,189 - root - INFO -> Array input size of the train loader: torch.Size([32, 1, 192, 84])
2024-05-28 13:08:38,209 - root - INFO -> Array output size of the train loader: torch.Size([32, 1, 192, 84])
2024-05-28 13:08:38,209 - root - INFO -> Val loader info: {'Number of samples': 2754, 'Batch size': 32, 'Number of batches': 86}
2024-05-28 13:08:38,228 - root - INFO -> Array input size of the val loader: torch.Size([32, 1, 192, 84])
2024-05-28 13:08:38,247 - root - INFO -> Array output size of the val loader: torch.Size([32, 1, 192, 84])
2024-05-28 13:08:39,385 - root - INFO -> --------------------------------------------------
2024-05-28 13:08:39,385 - root - INFO -> Starting training with model UNet that has 7762465 parameters
2024-05-28 13:08:39,385 - root - INFO -> Learning rate: 0.002
2024-05-28 13:08:39,385 - root - INFO -> --- Epoch: 0 ---
2024-05-28 13:08:39,385 - root - INFO -> Epoch: 0/100, Starting training...
2024-05-28 13:08:39,385 - root - INFO -> Loader length: 315
2024-05-28 13:08:39,385 - root - INFO -> Loader batch size: 32
2024-05-28 13:08:39,386 - root - INFO -> Loader drop last: True
2024-05-28 13:08:39,386 - root - INFO -> Loader num workers: 0
2024-05-28 13:08:39,386 - root - INFO -> Criterion: MSELoss()
2024-05-28 13:08:39,386 - root - INFO -> Physical loss: None
2024-05-28 13:08:39,499 - root - INFO -> Memory cleaned!
2024-05-28 13:09:44,339 - root - INFO -> Epoch: 0/100, Train loss = 0.001500
2024-05-28 13:09:44,340 - root - INFO -> Epoch: 0/100, Train MSELoss() = 0.001500
2024-05-28 13:09:44,340 - root - INFO -> Epoch: 0/100, Train PerCS() = 0.706006
2024-05-28 13:09:44,340 - root - INFO -> Epoch: 0/100, Train MSEeff() = 0.011727
2024-05-28 13:09:44,434 - root - INFO -> Train finished! Memory cleaned!
2024-05-28 13:09:44,434 - root - INFO -> --------------------------------------------------
2024-05-28 13:09:44,434 - root - INFO -> Epoch: 0/100, Starting validation...
2024-05-28 13:09:44,434 - root - INFO -> Loader length: 86
2024-05-28 13:09:44,434 - root - INFO -> Loader batch size: 32
2024-05-28 13:09:44,434 - root - INFO -> Loader drop last: True
2024-05-28 13:09:44,434 - root - INFO -> Loader num workers: 0
2024-05-28 13:09:44,434 - root - INFO -> Metrics: [MSELoss(), PerCS(), MSEeff()]
2024-05-28 13:09:44,434 - root - INFO -> Physical loss: None
2024-05-28 13:09:44,531 - root - INFO -> Memory cleaned!
2024-05-28 13:09:57,122 - root - INFO -> Epoch: 0/100, Val loss = 0.000267
2024-05-28 13:09:57,123 - root - INFO -> Epoch: 0/100, Val MSELoss() = 0.000267
2024-05-28 13:09:57,123 - root - INFO -> Epoch: 0/100, Val PerCS() = 0.798888
2024-05-28 13:09:57,123 - root - INFO -> Epoch: 0/100, Val MSEeff() = 0.009553
2024-05-28 13:09:57,222 - root - INFO -> Validation finished! Memory cleaned!
2024-05-28 13:09:57,222 - root - INFO -> --------------------------------------------------
2024-05-28 13:09:57,222 - root - INFO -> Learning rate: 0.002
2024-05-28 13:09:57,228 - root - INFO -> --- Epoch: 1 ---
2024-05-28 13:09:57,228 - root - INFO -> Epoch: 1/100, Starting training...
2024-05-28 13:09:57,229 - root - INFO -> Loader length: 315
2024-05-28 13:09:57,229 - root - INFO -> Loader batch size: 32
2024-05-28 13:09:57,229 - root - INFO -> Loader drop last: True
2024-05-28 13:09:57,229 - root - INFO -> Loader num workers: 0
2024-05-28 13:09:57,229 - root - INFO -> Criterion: MSELoss()
2024-05-28 13:09:57,229 - root - INFO -> Physical loss: None
2024-05-28 13:09:57,323 - root - INFO -> Memory cleaned!
2024-05-28 13:10:58,482 - root - INFO -> Epoch: 1/100, Train loss = 0.000226
2024-05-28 13:10:58,483 - root - INFO -> Epoch: 1/100, Train MSELoss() = 0.000226
2024-05-28 13:10:58,483 - root - INFO -> Epoch: 1/100, Train PerCS() = 0.807413
2024-05-28 13:10:58,483 - root - INFO -> Epoch: 1/100, Train MSEeff() = 0.008640
2024-05-28 13:10:58,578 - root - INFO -> Train finished! Memory cleaned!
2024-05-28 13:10:58,578 - root - INFO -> --------------------------------------------------
2024-05-28 13:10:58,596 - root - INFO -> Epoch: 1/100, Starting validation...
2024-05-28 13:10:58,597 - root - INFO -> Loader length: 86
2024-05-28 13:10:58,597 - root - INFO -> Loader batch size: 32
2024-05-28 13:10:58,597 - root - INFO -> Loader drop last: True
2024-05-28 13:10:58,597 - root - INFO -> Loader num workers: 0
2024-05-28 13:10:58,597 - root - INFO -> Metrics: [MSELoss(), PerCS(), MSEeff()]
2024-05-28 13:10:58,597 - root - INFO -> Physical loss: None
2024-05-28 13:10:58,738 - root - INFO -> Memory cleaned!
2024-05-28 13:11:11,279 - root - INFO -> Epoch: 1/100, Val loss = 0.000224
2024-05-28 13:11:11,279 - root - INFO -> Epoch: 1/100, Val MSELoss() = 0.000224
2024-05-28 13:11:11,279 - root - INFO -> Epoch: 1/100, Val PerCS() = 0.836964
2024-05-28 13:11:11,279 - root - INFO -> Epoch: 1/100, Val MSEeff() = 0.009551
2024-05-28 13:11:11,373 - root - INFO -> Validation finished! Memory cleaned!
2024-05-28 13:11:11,373 - root - INFO -> --------------------------------------------------
2024-05-28 13:11:11,373 - root - INFO -> Learning rate: 0.002
2024-05-28 13:11:11,373 - root - INFO -> --- Epoch: 2 ---
2024-05-28 13:11:11,373 - root - INFO -> Epoch: 2/100, Starting training...
2024-05-28 13:11:11,373 - root - INFO -> Loader length: 315
2024-05-28 13:11:11,373 - root - INFO -> Loader batch size: 32
2024-05-28 13:11:11,373 - root - INFO -> Loader drop last: True
2024-05-28 13:11:11,373 - root - INFO -> Loader num workers: 0
2024-05-28 13:11:11,373 - root - INFO -> Criterion: MSELoss()
2024-05-28 13:11:11,373 - root - INFO -> Physical loss: None
2024-05-28 13:11:11,468 - root - INFO -> Memory cleaned!
