{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUATION FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This file is to evaluate the loaded models with an specific validation keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.functional import crop\n",
    "import gc\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from Utils.logger import initialize_logger, get_logger\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import signal\n",
    "from Utils.config import (\n",
    "    USE_PHYSICAL_DATA,\n",
    "    PATH_DATASET,\n",
    "    IMG_PATH,\n",
    ")\n",
    "\n",
    "from Utils import (\n",
    "    metrics,\n",
    ")\n",
    "# Metrics\n",
    "metrics = [\n",
    "    torch.nn.MSELoss(),\n",
    "    metrics.PerCS()\n",
    "]\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LOCAL_SLP_DATASET_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))),'SLP/danaLab')\n",
    "SERVER_SLP_DATASET_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))))),'mnt/DADES2/SLP/SLP/danaLab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of the valuation patients:\n",
    "\n",
    "['00074', '00040', '00024', '00043', '00081', '00070', '00077', '00044', '00002','00079', '00091', '00087', '00078', '00047', '00031', '00069', '00039', '00086', '00009', '00092', '00064']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the numpy arrays of an specific image\n",
    "\n",
    "def select_file(path,patient,cover,img):\n",
    "\n",
    "    if os.path.isdir(os.path.join(path,patient)):\n",
    "        print('Patient:', patient)\n",
    "        patient_path = os.path.join(path,patient)\n",
    "        pm_np_path = os.path.join(patient_path,'PMarray')\n",
    "        ir_np_path = os.path.join(patient_path,'IRraw')\n",
    "\n",
    "        if os.path.isdir(pm_np_path) and os.path.isdir(ir_np_path):\n",
    "            pm_cover_path = os.path.join(pm_np_path,cover)\n",
    "            print('PM cover path:',pm_cover_path)\n",
    "            ir_cover_path = os.path.join(ir_np_path,cover)\n",
    "            print('IR cover path:',ir_cover_path)\n",
    "\n",
    "            if os.path.isdir(pm_cover_path) and os.path.isdir(ir_cover_path):\n",
    "                pm_file_path = os.path.join(pm_cover_path,img)\n",
    "                ir_file_path = os.path.join(ir_cover_path,img)\n",
    "\n",
    "                return pm_file_path,ir_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all the files of an especific cover\n",
    "\n",
    "patients = ['00074', '00040', '00024', '00043', '00081', '00070', '00077', '00044',\n",
    "            '00002','00079', '00091', '00087', '00078', '00047', '00031', '00069',\n",
    "            '00039', '00086', '00009', '00092', '00064']\n",
    "\n",
    "covers = ['cover1','cover2','uncover']\n",
    "\n",
    "def cover_files(path,patients,cover):\n",
    "    pm_total_files = []\n",
    "    ir_total_files = []\n",
    "    \n",
    "    for patient in patients:\n",
    "        if os.path.isdir(os.path.join(path,patient)):\n",
    "            print('Patient:', patient)\n",
    "            patient_path = os.path.join(path,patient)\n",
    "            pm_np_path = os.path.join(patient_path,'PMarray')\n",
    "            ir_np_path = os.path.join(patient_path,'IRraw')\n",
    "\n",
    "        if os.path.isdir(pm_np_path) and os.path.isdir(ir_np_path):\n",
    "            pm_cover_path = os.path.join(pm_np_path,cover)\n",
    "            ir_cover_path = os.path.join(ir_np_path,cover)\n",
    "            filenames_pm = os.listdir(pm_cover_path)\n",
    "            filenames_ir = os.listdir(ir_cover_path)\n",
    "\n",
    "            for pm_file,ir_file in zip(filenames_pm,filenames_ir):\n",
    "                pm_total_files.append(os.path.join(pm_cover_path,pm_file))\n",
    "                ir_total_files.append(os.path.join(ir_cover_path,ir_file))\n",
    "\n",
    "    return pm_total_files,ir_total_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all the files of a patient\n",
    "\n",
    "def patient_files(path,patient):\n",
    "    pm_total_files = []\n",
    "    ir_total_files = []\n",
    "    \n",
    "    if os.path.isdir(os.path.join(path,patient)):\n",
    "        print('Patient:', patient)\n",
    "        patient_path = os.path.join(path,patient)\n",
    "        pm_np_path = os.path.join(patient_path,'PMarray')\n",
    "        ir_np_path = os.path.join(patient_path,'IRraw')\n",
    "\n",
    "        for category_pm,category_ir in zip(os.listdir(pm_np_path),os.listdir(ir_np_path)):\n",
    "            pm_cover_path = os.path.join(pm_np_path,category_pm)\n",
    "            ir_cover_path = os.path.join(ir_np_path,category_ir)\n",
    "            filenames_pm = os.listdir(pm_cover_path)\n",
    "            filenames_ir = os.listdir(ir_cover_path)\n",
    "\n",
    "            for pm_file,ir_file in zip(filenames_pm,filenames_ir):\n",
    "                pm_total_files.append(os.path.join(pm_cover_path,pm_file))\n",
    "                ir_total_files.append(os.path.join(ir_cover_path,ir_file))\n",
    "\n",
    "    return pm_total_files,ir_total_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    # Dataset for the random option\n",
    "    # Includes:\n",
    "    # - IR arrays\n",
    "    # - PR arrays\n",
    "    # Physical data\n",
    "    def __init__(self, ir_paths, pm_paths, p_data, transform=None):\n",
    "\n",
    "        self.ir_paths = ir_paths\n",
    "        self.pm_paths = pm_paths\n",
    "        self.p_data = p_data\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ir_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        input_path = self.ir_paths[index]\n",
    "        output_path = self.pm_paths[index]\n",
    "\n",
    "        input_array = self.load_array(input_path)\n",
    "        output_array = self.load_array(output_path)\n",
    "        input_array = input_array.astype(np.float32)\n",
    "        output_array = output_array.astype(np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            input_array = self.transform['input'](input_array)\n",
    "\n",
    "            if PATH_DATASET == 'Server':\n",
    "                parts = str(output_path.split(\"/\")[-4])\n",
    "            else:\n",
    "                parts = str(output_path.split(\"\\\\\")[-4])\n",
    "            number = int(parts)\n",
    "            p_vector = self.p_data.iloc[number-1]\n",
    "            weight = p_vector[1]\n",
    "            tensor_data = torch.tensor(p_vector.values)\n",
    "\n",
    "            # Applying median filter\n",
    "            median_array = signal.medfilt2d(output_array)\n",
    "            max_array = np.maximum(output_array, median_array)\n",
    "\n",
    "            area_m = 1.03226 / 10000\n",
    "            ideal_pressure = weight * 9.81 / (area_m * 1000)\n",
    "\n",
    "            output_array = (max_array / np.sum(max_array)) * ideal_pressure\n",
    "            output_array = self.transform['output'](output_array)\n",
    "\n",
    "            if USE_PHYSICAL_DATA:\n",
    "                return input_array, output_array, tensor_data\n",
    "            else:\n",
    "                return input_array, output_array\n",
    "\n",
    "    def load_array(self, path):\n",
    "        # Load the array\n",
    "        array = np.load(path)\n",
    "        return array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cover_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Function to get the files that we want and do the transforms and create a dataloader to pass the model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m pm_files, ir_files \u001b[38;5;241m=\u001b[39m cover_files(LOCAL_SLP_DATASET_PATH,patients,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcover1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m dic \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mir\u001b[39m\u001b[38;5;124m'\u001b[39m: ir_files, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpm\u001b[39m\u001b[38;5;124m'\u001b[39m: pm_files}\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcrop_array\u001b[39m(array):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cover_files' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to get the files that we want and do the transforms and create a dataloader to pass the model\n",
    "\n",
    "pm_files, ir_files = cover_files(LOCAL_SLP_DATASET_PATH, patients, 'cover1')\n",
    "\n",
    "dic = {'ir': ir_files, 'pm': pm_files}\n",
    "\n",
    "def crop_array(array):\n",
    "        return crop(array,7, 29, 140, 66)\n",
    "\n",
    "# Data transformation if needed\n",
    "transform = {\n",
    "        'input': transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Lambda(crop_array),  \n",
    "                    transforms.Resize((192, 84)),\n",
    "\t\t            transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "                    ]),\n",
    "        'output': transforms.Compose([transforms.ToTensor()])}\n",
    "\n",
    "p_data = pd.read_csv(os.path.join(LOCAL_SLP_DATASET_PATH, 'physiqueData.csv'))\n",
    "p_data['gender'] = p_data['gender'].str.strip()\n",
    "p_data = pd.get_dummies(p_data, columns=['gender'])\n",
    "p_data = p_data.drop('sub_idx',axis=1)\n",
    "p_data['gender_male'] = p_data['gender_male'].astype(int)\n",
    "p_data['gender_female'] = p_data['gender_female'].astype(int)\n",
    "\n",
    "\n",
    "def create_dataloader(dic,p_data,transform):\n",
    "    \n",
    "    dataset = CustomDataset(dic['ir'], dic['pm'], p_data, transform=transform)\n",
    "    print('Len dataset:',len(dataset))\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "            dataset, batch_size=1, shuffle=False, num_workers=0, drop_last=True)\n",
    "    \n",
    "    val_dataset_info = {\n",
    "        'Number of samples': len(val_loader.dataset),\n",
    "        'Batch size': val_loader.batch_size,\n",
    "        'Number of batches': len(val_loader)\n",
    "        }\n",
    "    \n",
    "    print(f\"Val loader info: {val_dataset_info}\")\n",
    "\n",
    "    return val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate with a model loaded the files that we want with the metrics\n",
    "\n",
    "def evaluation(model,model_file,metrics,val_loader):\n",
    "    model.load_state_dict(torch.load(model_file, map_location=torch.device('cpu')))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    total_metric = [0, 0]\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_idx, (input_images, target_images) in enumerate(val_loader, 1):\n",
    "\n",
    "            input_img= input_images.to(DEVICE)\n",
    "            target_img = target_images.to(DEVICE)\n",
    "\n",
    "            output_img = model(input_img)\n",
    "\n",
    "            for i, metric in enumerate(metrics):\n",
    "\n",
    "                val_metric = metric(output_img, target_img)\n",
    "\n",
    "                total_metric[i] += val_metric\n",
    "\n",
    "            # Free memory in each iteration\n",
    "            del input_images\n",
    "            del target_images\n",
    "            del val_loss\n",
    "            torch.cuda.empty_cache()  # Clean CUDA Cache if used GPU\n",
    "            gc.collect()  # Collect trash to free memory not used\n",
    "\n",
    "    epoch_metric = [total_metric[0] /\n",
    "                    len(val_loader), total_metric[1] / len(val_loader)]\n",
    "    \n",
    "    print(metrics)\n",
    "    print(epoch_metric)\n",
    "\n",
    "    last_value_metrics = [0,0]\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "\n",
    "        val_metric = metric(output_img, target_img)\n",
    "        last_value_metrics[i] = val_metric\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    axes[0].imshow(input_images.squeeze().cpu().numpy())\n",
    "    axes[0].set_title('Input Image')\n",
    "\n",
    "    axes[0].imshow(target_images.squeeze().cpu().numpy())\n",
    "    axes[0].set_title('Target Image')\n",
    "\n",
    "    axes[1].imshow(output_img.squeeze().cpu().numpy())\n",
    "    axes[1].set_title('Output Image')\n",
    "\n",
    "    \n",
    "\n",
    "    fig.suptitle('Input, Target and Output Image', fontsize=12)\n",
    "    fig.text(0.5, 0.01, f': {last_value_metrics:.4f}', ha='center')\n",
    "    plt.savefig(os.path.join(IMG_PATH,'Comparing_output_model.png'))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
