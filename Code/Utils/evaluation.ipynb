{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUATION FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This file is to evaluate the loaded models with an specific validation keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LOCAL_SLP_DATASET_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))),'SLP/danaLab')\n",
    "SERVER_SLP_DATASET_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))))),'mnt/DADES2/SLP/SLP/danaLab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of the valuation patients:\n",
    "\n",
    "['00082', '00083', '00084', '00085', '00086', '00087', '00088', '00089', '00090', '00091', '00092', '00093', '00094', '00095', '00096', '00097', '00098', '00099', '00100', '00101', '00102']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the numpy arrays of an specific image\n",
    "\n",
    "def select_file(path,patient,cover,img):\n",
    "\n",
    "    if os.path.isdir(os.path.join(path,patient)):\n",
    "        print('Patient:', patient)\n",
    "        patient_path = os.path.join(path,patient)\n",
    "        pm_np_path = os.path.join(patient_path,'PMarray')\n",
    "        ir_np_path = os.path.join(patient_path,'IRraw')\n",
    "\n",
    "        if os.path.isdir(pm_np_path) and os.path.isdir(ir_np_path):\n",
    "            pm_cover_path = os.path.join(pm_np_path,cover)\n",
    "            print('PM cover path:',pm_cover_path)\n",
    "            ir_cover_path = os.path.join(ir_np_path,cover)\n",
    "            print('IR cover path:',ir_cover_path)\n",
    "\n",
    "            if os.path.isdir(pm_cover_path) and os.path.isdir(ir_cover_path):\n",
    "                pm_file_path = os.path.join(pm_cover_path,img)\n",
    "                ir_file_path = os.path.join(ir_cover_path,img)\n",
    "            \n",
    "                pm_np = np.load(pm_file_path)\n",
    "                ir_np = np.load(ir_file_path)\n",
    "\n",
    "                return pm_np,ir_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all the files of an especific cover\n",
    "\n",
    "patients = ['00082', '00083', '00084', '00085', '00086', '00087', '00088', '00089',\n",
    "            '00090', '00091', '00092', '00093', '00094', '00095', '00096', '00097',\n",
    "            '00098', '00099', '00100', '00101', '00102']\n",
    "\n",
    "covers = ['cover1','cover2','uncover']\n",
    "\n",
    "def cover_files(path,patients,cover):\n",
    "    pm_total_files = []\n",
    "    ir_total_files = []\n",
    "    \n",
    "    for patient in patients:\n",
    "        if os.path.isdir(os.path.join(path,patient)):\n",
    "            print('Patient:', patient)\n",
    "            patient_path = os.path.join(path,patient)\n",
    "            pm_np_path = os.path.join(patient_path,'PMarray')\n",
    "            ir_np_path = os.path.join(patient_path,'IRraw')\n",
    "\n",
    "        if os.path.isdir(pm_np_path) and os.path.isdir(ir_np_path):\n",
    "            pm_cover_path = os.path.join(pm_np_path,cover)\n",
    "            ir_cover_path = os.path.join(ir_np_path,cover)\n",
    "            filenames_pm = os.listdir(pm_cover_path)\n",
    "            filenames_ir = os.listdir(ir_cover_path)\n",
    "\n",
    "            for pm_file,ir_file in zip(filenames_pm,filenames_ir):\n",
    "                pm_total_files.append(np.load(os.path.join(pm_cover_path,pm_file)))\n",
    "                ir_total_files.append(np.load(os.path.join(ir_cover_path,ir_file)))\n",
    "\n",
    "    return pm_total_files,ir_total_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all the files of a patient\n",
    "\n",
    "def patient_files(path,patient):\n",
    "    pm_total_files = []\n",
    "    ir_total_files = []\n",
    "    \n",
    "    if os.path.isdir(os.path.join(path,patient)):\n",
    "        print('Patient:', patient)\n",
    "        patient_path = os.path.join(path,patient)\n",
    "        pm_np_path = os.path.join(patient_path,'PMarray')\n",
    "        ir_np_path = os.path.join(patient_path,'IRraw')\n",
    "\n",
    "        for category_pm,category_ir in zip(os.listdir(pm_np_path),os.listdir(ir_np_path)):\n",
    "            pm_cover_path = os.path.join(pm_np_path,category_pm)\n",
    "            ir_cover_path = os.path.join(ir_np_path,category_ir)\n",
    "            filenames_pm = os.listdir(pm_cover_path)\n",
    "            filenames_ir = os.listdir(ir_cover_path)\n",
    "\n",
    "            for pm_file,ir_file in zip(filenames_pm,filenames_ir):\n",
    "                pm_total_files.append(np.load(os.path.join(pm_cover_path,pm_file)))\n",
    "                ir_total_files.append(np.load(os.path.join(ir_cover_path,ir_file)))\n",
    "\n",
    "    return pm_total_files,ir_total_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the files that we want and do the transforms and create a dataloader to pass the model\n",
    "\n",
    "def create_dataloader():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate with a model loaded the files that we want with the metrics\n",
    "\n",
    "def evaluation(model,model_file,metric,files):\n",
    "    model.load_state_dict(torch.load(model_file, map_location=torch.device('cpu')))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for input_img, target_img in val_loader:\n",
    "            break\n",
    "\n",
    "        input_img = input_img.to(DEVICE)\n",
    "        target_img = target_img.to(DEVICE)\n",
    "\n",
    "        output_img = model(input_img)\n",
    "        loss = criterion(output_img[0], target_img[0])\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "        axes[0].imshow(target_img[0].squeeze().cpu().numpy())\n",
    "        axes[0].set_title('Target Image')\n",
    "\n",
    "        axes[1].imshow(output_img[0].squeeze().cpu().numpy())\n",
    "        axes[1].set_title('Output Image')\n",
    "\n",
    "        fig.suptitle('Comparison of Target and Output Images', fontsize=12)\n",
    "        fig.text(0.5, 0.01, f'Loss: {loss.item():.4f}', ha='center')\n",
    "        plt.savefig(os.path.join(IMG_PATH,'Comparing_output_MSE.png'))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
